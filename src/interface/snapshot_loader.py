import json
import pandas as pd
import geopandas as gpd
from pathlib import Path
import logging
from typing import Dict, Optional, Tuple

class SnapshotLoader:
    """
    Loader for graph snapshots generated by the pipeline.
    Ensures the Dashboard visualizes exact static states instead of reconstructing them.
    """
    
    def __init__(self):
        # Paths to snapshots
        self.data_dir = Path(__file__).parent.parent.parent / "data" / "03_processed"
        self.snapshots = {
            "step1": self.data_dir / "snapshot_step1_initial.json",
            "step5": self.data_dir / "snapshot_step5_post_unitary.json",
            "step6": self.data_dir / "snapshot_step6_sede_consolidation.json",
            "step8": self.data_dir / "snapshot_step8_final.json"  # Uses final snapshot (includes 8.1 + 8.5)
        }
    
    def load_snapshot(self, step_key: str) -> Dict:
        """Loads the raw JSON snapshot."""
        path = self.snapshots.get(step_key)
        if not path or not path.exists():
            logging.warning(f"⚠️ Snapshot {step_key} not found at {path}")
            return {}
            
        try:
            with open(path, 'r', encoding='utf-8') as f:
                data = json.load(f)
                logging.info(f"✅ Snapshot {step_key} loaded successfully.")
                return data
        except Exception as e:
            logging.error(f"❌ Error loading snapshot {step_key}: {e}")
            return {}

    def get_snapshot_dataframe(self, step_key: str) -> pd.DataFrame:
        """
        Converts a snapshot into a Pandas DataFrame suitable for merging with geometries.
        
        Returns:
            DataFrame with columns: [cd_mun, utp_id, sede_utp, regiao_metropolitana, nm_mun, color]
        """
        data = self.load_snapshot(step_key)
        if not data:
            return pd.DataFrame()
            
        nodes = data.get("nodes", {})
        coloring = data.get("coloring", {})
        
        rows = []
        for node_id_str, attrs in nodes.items():
            # Only process municipalities (integer-like IDs)
            if not node_id_str.isdigit():
                continue
                
            cd_mun_str = str(node_id_str)
            
            # Extract basic attributes
            row = {
                "cd_mun": cd_mun_str,
                "utp_id": str(attrs.get("utp_id", "SEM_UTP")),
                "sede_utp": bool(attrs.get("sede_utp", False)),
                "regiao_metropolitana": attrs.get("regiao_metropolitana", "SEM_RM"),
                "nm_mun": attrs.get("name", ""),
                "nm_mun": attrs.get("name", ""),
                "color_id": coloring.get(cd_mun_str, coloring.get(str(cd_mun_str), 0))
            }
            # Fallback: check if coloring keys are ints in the JSON (unlikely but possible)
            if row['color_id'] == 0:
                 row['color_id'] = coloring.get(int(cd_mun_str), 0)
                 
            rows.append(row)
            
        df = pd.DataFrame(rows)
        return df

    def get_geodataframe_for_step(self, step_key: str, base_gdf: gpd.GeoDataFrame) -> gpd.GeoDataFrame:
        """
        Returns a GeoDataFrame fully synchronized with the snapshot state.
        
        1. Takes base geometries (immutable).
        2. Merges snapshot attributes (mutable state).
        """
        if base_gdf is None or base_gdf.empty:
            return None
            
        df_snapshot = self.get_snapshot_dataframe(step_key)
        
        if df_snapshot.empty:
            return None
            
        # Ensure join keys are strings
        base_gdf = base_gdf.copy()
        if 'CD_MUN' in base_gdf.columns:
            base_gdf['CD_MUN'] = base_gdf['CD_MUN'].astype(str)
        
        # Drop old attributes to prevent conflicts (and SUFFIX creation)
        # We must drop 'nm_mun' and 'NM_MUN' so the snapshot's 'nm_mun' survives without _x/_y
        cols_to_drop = [
            'utp_id', 'sede_utp', 'regiao_metropolitana', 'nm_sede', 'color', 'COLOR_ID', 'UTP_ID',
            'nm_mun', 'NM_MUN', 'NM_MUN_x', 'NM_MUN_y'
        ]
        base_gdf = base_gdf.drop(columns=[c for c in cols_to_drop if c in base_gdf.columns], errors='ignore')
        
        # Merge
        gdf_merged = base_gdf.merge(
            df_snapshot,
            left_on='CD_MUN',
            right_on='cd_mun',
            how='inner'  # Only keep municipalities present in snapshot
        )
        
        # Calculate derived 'nm_sede' for popup/tooltip
        try:
            # Check if required columns exist (handling potential suffix issues if they persist)
            utp_col = 'utp_id'
            nm_col = 'nm_mun'
            
            if utp_col not in gdf_merged.columns:
                # Fallback check for suffixes
                if 'utp_id_x' in gdf_merged.columns: utp_col = 'utp_id_x'
                elif 'utp_id_y' in gdf_merged.columns: utp_col = 'utp_id_y'
            
            if nm_col not in gdf_merged.columns:
                if 'nm_mun_x' in gdf_merged.columns: nm_col = 'nm_mun_x'
                elif 'nm_mun_y' in gdf_merged.columns: nm_col = 'nm_mun_y'
            
            # Find who is currently the sede for each utp
            sedes_df = gdf_merged[gdf_merged['sede_utp'] == True][[utp_col, nm_col]]
            sede_map = sedes_df.set_index(utp_col)[nm_col].to_dict()
            
            gdf_merged['nm_sede'] = gdf_merged[utp_col].map(sede_map).fillna("DESCONHECIDO")
            
            # Standardize output columns if they were suffixed
            if utp_col != 'utp_id':
                gdf_merged['utp_id'] = gdf_merged[utp_col]
            if nm_col != 'nm_mun':
                 gdf_merged['nm_mun'] = gdf_merged[nm_col]
            
            # Ensure CD_MUN (uppercase) exists and is used
            if 'CD_MUN' not in gdf_merged.columns and 'cd_mun' in gdf_merged.columns:
                 gdf_merged['CD_MUN'] = gdf_merged['cd_mun']

            # Ensure NM_MUN (uppercase) exists (required by Folium Tooltips)
            if 'NM_MUN' not in gdf_merged.columns and 'nm_mun' in gdf_merged.columns:
                 gdf_merged['NM_MUN'] = gdf_merged['nm_mun']
            
            # Ensure uf (lowercase) exists
            if 'uf' not in gdf_merged.columns:
                if 'UF' in gdf_merged.columns:
                    gdf_merged['uf'] = gdf_merged['UF']
                elif 'SIGLA' in gdf_merged.columns:
                    gdf_merged['uf'] = gdf_merged['SIGLA']
                elif 'SIGLA_UF' in gdf_merged.columns:
                    gdf_merged['uf'] = gdf_merged['SIGLA_UF']
                  
        except Exception as e:
            logging.error(f"❌ Error deriving metadata in SnapshotLoader: {e}. Columns: {gdf_merged.columns.tolist()}")
            # Create empty columns to avoid crash downstream
            cols_needed = ['nm_sede', 'NM_MUN', 'CD_MUN', 'uf']
            for c in cols_needed:
                if c not in gdf_merged.columns:
                    gdf_merged[c] = "ERRO"
        
        return gdf_merged
    
    def get_complete_dataframe_with_flows(self, step_key: str = 'step8') -> pd.DataFrame:
        """
        Returns a complete DataFrame with both snapshot UTP assignments and original flow data.
        
        The snapshot contains updated UTP assignments (from consolidations/validations)
        but does NOT contain modal_matriz flow data. We need to merge:
        - UTP assignments from snapshot (step8 = final state)
        - Flow data (modal_matriz) from initialization.json (original, unchanged)
        
        Args:
            step_key: Snapshot step to load ('step8' for border validation)
            
        Returns:
            DataFrame with columns: cd_mun, nm_mun, utp_id (updated), sede_utp (updated),
                                   regiao_metropolitana, uf, modal_matriz, + other original data
        """
        from src.utils import DataLoader
        
        # Load snapshot for updated UTP assignments
        df_snapshot = self.get_snapshot_dataframe(step_key)
        
        if df_snapshot.empty:
            logging.warning(f"⚠️ Snapshot {step_key} is empty, falling back to initialization.json")
            return DataLoader.get_municipios_dataframe()
        
        # Load original data for flow information
        df_original = DataLoader.get_municipios_dataframe()
        
        if df_original.empty:
            logging.error("❌ Could not load initialization.json")
            return pd.DataFrame()
        
        # Ensure consistent types for merge
        df_snapshot['cd_mun'] = df_snapshot['cd_mun'].astype(str)
        df_original['cd_mun'] = df_original['cd_mun'].astype(str)
        
        # Merge: Use snapshot UTP data, but keep all original columns (including modal_matriz)
        # We'll update utp_id, sede_utp from snapshot, but keep everything else from original
        df_merged = df_original.copy()
        
        # Update UTP-related columns from snapshot
        snapshot_updates = df_snapshot[['cd_mun', 'utp_id', 'sede_utp']].copy()
        
        # Create a mapping to update the original dataframe
        df_merged = df_merged.set_index('cd_mun')
        snapshot_updates = snapshot_updates.set_index('cd_mun')
        
        # Update only the UTP-related columns
        df_merged.update(snapshot_updates)
        df_merged = df_merged.reset_index()
        
        logging.info(f"✅ Merged snapshot {step_key} with flow data: {len(df_merged)} municipalities")
        
        return df_merged