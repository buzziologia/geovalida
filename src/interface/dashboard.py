# src/interface/dashboard.py
import streamlit as st
import pandas as pd
import geopandas as gpd
import folium
import json
from pathlib import Path
from datetime import datetime
from src.utils import DataLoader
from src.interface.consolidation_loader import ConsolidationLoader
from src.run_consolidation import run_consolidation
from src.pipeline.sede_analyzer import SedeAnalyzer
from src.interface.components import sede_comparison


# ===== CONFIGURA√á√ÉO DA P√ÅGINA =====
st.set_page_config(
    page_title="GeoValida - Consolida√ß√£o Territorial",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS customizado
st.markdown("""
<style>
    :root {
        --primary-color: #1351B4;
    }
    [data-testid="stMetricValue"] {
        color: #1351B4;
        font-weight: bold;
    }
    .step-badge {
        display: inline-block;
        padding: 4px 12px;
        border-radius: 20px;
        font-weight: 600;
        font-size: 0.85rem;
    }
    .step-initial { background-color: #e3f2fd; color: #1351B4; }
    .step-final { background-color: #e8f5e9; color: #2e7d32; }
    .status-badge {
        display: inline-block;
        padding: 6px 16px;
        border-radius: 20px;
        font-weight: 600;
        font-size: 0.9rem;
    }
    .status-executed { background-color: #d4edda; color: #155724; }
    .status-pending { background-color: #fff3cd; color: #856404; }
</style>
""", unsafe_allow_html=True)


@st.cache_data(show_spinner=True, hash_funcs={gpd.GeoDataFrame: id})
def get_geodataframe(shapefile_path, df_municipios):
    """Carrega, processa e simplifica o shapefile com cache."""
    if not shapefile_path.exists():
        return None

    try:
        gdf = gpd.read_file(shapefile_path)
        
        # Reprojetar para WGS84 (EPSG:4326) - Folium espera este CRS
        # O shapefile original est√° em SIRGAS2000 (EPSG:4674)
        if gdf.crs and gdf.crs.to_epsg() != 4326:
            gdf = gdf.to_crs(epsg=4326)
        
        # Converter IDs para string
        gdf['CD_MUN'] = gdf['CD_MUN'].astype(str)
        # Garantir c√≥pia para n√£o afetar cache original do pandas se houver
        df_mun_copy = df_municipios.copy()
        df_mun_copy['cd_mun'] = df_mun_copy['cd_mun'].astype(str)
        
        # Juntar dados
        gdf = gdf.merge(df_mun_copy[['cd_mun', 'uf', 'utp_id', 'sede_utp', 'regiao_metropolitana', 'nm_mun']], 
                       left_on='CD_MUN', right_on='cd_mun', how='left')
        
        # Identificar nomes das sedes
        df_sedes = df_mun_copy[df_mun_copy['sede_utp'] == True][['utp_id', 'nm_mun']].set_index('utp_id')
        sede_mapper = df_sedes['nm_mun'].to_dict()
        gdf['nm_sede'] = gdf['utp_id'].map(sede_mapper).fillna('')
        
        # Simplificar geometria com preserva√ß√£o de topologia - tolerance de 0.002 graus (~200m)
        gdf['geometry'] = gdf.geometry.simplify(tolerance=0.002, preserve_topology=True)
        gdf['regiao_metropolitana'] = gdf['regiao_metropolitana'].fillna('')
        
        # Manter apenas colunas essenciais
        cols_to_keep = ['NM_MUN', 'CD_MUN', 'geometry', 'uf', 'utp_id', 'sede_utp', 'regiao_metropolitana', 'nm_sede']
        existing_cols = [c for c in cols_to_keep if c in gdf.columns]
        gdf = gdf[existing_cols]
        
        return gdf
    except Exception as e:
        st.error(f"Erro no processamento do mapa: {e}")
        return None


def render_map(gdf_filtered, title="Mapa"):
    """Fun√ß√£o auxiliar para renderizar um mapa folium."""
    if gdf_filtered is None or gdf_filtered.empty:
        st.info("Nenhum dado para visualizar neste filtro.")
        return
    
    # Criar cores por UTP com Paleta Pastel
    utps_unique = gdf_filtered['utp_id'].dropna().unique()
    colors = {}
    PASTEL_PALETTE = [
        '#8dd3c7', '#ffffb3', '#bebada', '#fb8072', '#80b1d3', '#fdb462', 
        '#b3de69', '#fccde5', '#d9d9d9', '#bc80bd', '#ccebc5', '#ffed6f',
        '#a6cee3', '#b2df8a', '#fb9a99', '#fdbf6f', '#cab2d6', '#ffff99'
    ]
    
    for i, utp in enumerate(sorted(utps_unique)):
        colors[utp] = PASTEL_PALETTE[i % len(PASTEL_PALETTE)]
    
    gdf_filtered = gdf_filtered.copy()
    gdf_filtered['color'] = gdf_filtered['utp_id'].map(colors)
    
    # Criar mapa folium
    m = folium.Map(
        location=[-15, -55],
        zoom_start=4,
        tiles="CartoDB positron",
        prefer_canvas=True,
        control_scale=True
    )
    
    # Fit bounds autom√°ticos
    if not gdf_filtered.empty:
        bounds = gdf_filtered.total_bounds
        m.fit_bounds([[bounds[1], bounds[0]], [bounds[3], bounds[2]]], padding=(0.05, 0.05))
    
    # Separar munic√≠pios regulares e sedes
    gdf_members = gdf_filtered[~gdf_filtered['sede_utp']].copy()
    gdf_seats = gdf_filtered[gdf_filtered['sede_utp']].copy()
    
    # Adicionar primeira camada: Munic√≠pios regulares
    if not gdf_members.empty:
        folium.GeoJson(
            gdf_members.to_json(),
            style_function=lambda x: {
                'fillColor': x['properties'].get('color', '#cccccc'),
                'color': '#ffffff',
                'weight': 0.3,
                'fillOpacity': 0.9
            },
            tooltip=folium.GeoJsonTooltip(
                fields=['NM_MUN', 'utp_id', 'regiao_metropolitana', 'uf', 'nm_sede'],
                aliases=['Munic√≠pio:', 'UTP:', 'RM:', 'UF:', 'Sede:'],
                localize=True,
                sticky=False
            ),
            popup=folium.GeoJsonPopup(
                fields=['NM_MUN', 'CD_MUN', 'utp_id', 'regiao_metropolitana', 'uf', 'nm_sede'],
                aliases=['Munic√≠pio', 'C√≥digo IBGE', 'UTP', 'RM', 'UF', 'Sede UTP']
            )
        ).add_to(m)
    
    # Adicionar segunda camada: Sedes com destaque
    if not gdf_seats.empty:
        folium.GeoJson(
            gdf_seats.to_json(),
            style_function=lambda x: {
                'fillColor': x['properties'].get('color', '#cccccc'),
                'color': '#000000',
                'weight': 3.0,
                'fillOpacity': 1.0
            },
            tooltip=folium.GeoJsonTooltip(
                fields=['NM_MUN', 'utp_id', 'regiao_metropolitana', 'uf', 'nm_sede'],
                aliases=['Munic√≠pio Sede:', 'UTP:', 'RM:', 'UF:', 'Sede:'],
                localize=True,
                sticky=False
            ),
            popup=folium.GeoJsonPopup(
                fields=['NM_MUN', 'CD_MUN', 'utp_id', 'regiao_metropolitana', 'uf', 'nm_sede'],
                aliases=['Munic√≠pio (SEDE)', 'C√≥digo IBGE', 'UTP', 'RM', 'UF', 'Sede UTP']
            )
        ).add_to(m)
    
    map_html = m._repr_html_()
    st.components.v1.html(map_html, height=600, scrolling=False)


def render_dashboard(manager):
    """Dashboard com visualiza√ß√£o do pipeline de consolida√ß√£o territorial."""
    
    # === LOAD CONSOLIDATION CACHE ===
    consolidation_loader = ConsolidationLoader()
    
    # === HEADER ===
    col1, col2, col3 = st.columns([2, 1, 1])
    with col1:
        st.title("GeoValida - Consolida√ß√£o Territorial")
        st.markdown("Visualiza√ß√£o da distribui√ß√£o inicial e p√≥s-consolida√ß√£o de UTPs")
    
    with col3:
        status_class = "status-executed" if consolidation_loader.is_executed() else "status-pending"
        status_text = "Consolidado" if consolidation_loader.is_executed() else "Pendente"
        st.markdown(f"<div class='status-badge {status_class}'>{status_text}</div>", unsafe_allow_html=True)
    
    # === SIDEBAR - FILTROS & CONTROLES ===
    with st.sidebar:
        st.markdown("### Filtros")
        st.markdown("---")
        
        # Carregar dados
        data_loader = DataLoader()
        df_municipios = data_loader.get_municipios_dataframe()
        metadata = data_loader.get_metadata()
        
        if df_municipios.empty:
            st.error("Falha ao carregar dados.")
            return
        
        # Filtro por UF
        ufs = sorted(df_municipios['uf'].unique().tolist())
        all_ufs = st.checkbox("Brasil Completo", value=True)
        
        if all_ufs:
            selected_ufs = ufs
            st.multiselect("Estados (UF)", ufs, default=ufs, disabled=True)
        else:
            selected_ufs = st.multiselect("Estados (UF)", ufs, default=[])
        
        # Filtro por UTP
        utps_list = sorted(df_municipios['utp_id'].unique().tolist())
        all_utps = st.checkbox("Todas as UTPs", value=False)
        
        if all_utps:
            selected_utps = utps_list
            st.multiselect("UTPs", utps_list, default=utps_list, disabled=True)
        else:
            selected_utps = st.multiselect("UTPs", utps_list, default=[])
        
        st.markdown("---")
        st.caption(f"Dados de: {metadata.get('timestamp', 'N/A')[:10]}")
        
        # === SE√á√ÉO DE CONSOLIDA√á√ÉO ===
        st.markdown("---")
        st.markdown("### Consolida√ß√£o")
        
        if consolidation_loader.is_executed():
            summary = consolidation_loader.get_summary()
            
            # Verifica se houve mudan√ßas ou n√£o
            if summary['total_consolidations'] > 0:
                st.success("Consolida√ß√£o em cache")
                st.metric("Consolida√ß√µes", summary['total_consolidations'])
                st.metric("UTPs Reduzidas", f"{summary['unique_sources']} ‚Üí {summary['unique_targets']}")
            else:
                st.info("Consolida√ß√£o executada - nenhuma mudan√ßa necess√°ria")
                st.caption("Todos os munic√≠pios j√° est√£o corretamente organizados.")
            
            col1, col2 = st.columns(2)
            with col1:
                if st.button("Rodar Agora", use_container_width=True, help="Executa o pipeline completo de consolida√ß√£o (Fluxos + REGIC)"):
                    with st.spinner("Executando pipeline..."):
                        if run_consolidation():
                            st.success("Sucesso!")
                            st.rerun()
                        else:
                            st.error("Falha na execu√ß√£o.")
            
            with col2:
                if st.button("Limpar Cache", use_container_width=True):
                    consolidation_loader.clear()
                    st.rerun()
        else:
            st.warning("Nenhuma consolida√ß√£o em cache")
            if st.button("Executar Consolida√ß√£o", use_container_width=True):
                with st.spinner("Executando pipeline..."):
                    if run_consolidation():
                        st.success("Sucesso!")
                        st.rerun()
                    else:
                        st.error("Falha na execu√ß√£o.")
    
    # Aplicar filtros
    df_filtered = df_municipios[df_municipios['uf'].isin(selected_ufs)].copy()
    if selected_utps:
        df_filtered = df_filtered[df_filtered['utp_id'].isin(selected_utps)]
    
    # Carregar shapefile
    shapefile_path = Path(__file__).parent.parent.parent / "data" / "01_raw" / "shapefiles" / "BR_Municipios_2024.shp"
    gdf = get_geodataframe(shapefile_path, df_municipios)
    
    # === TABS ===
    tab1, tab2, tab3 = st.tabs([
        "Distribui√ß√£o Inicial",
        "P√≥s-Consolida√ß√£o",
        "An√°lise de Depend√™ncias"
    ])
    
    # ==== TAB 1: DISTRIBUI√á√ÉO INICIAL ====
    with tab1:
        st.markdown("### <span class='step-badge step-initial'>INICIAL</span> Situa√ß√£o Atual", unsafe_allow_html=True)
        st.markdown("Mapa da distribui√ß√£o atual das UTPs antes da consolida√ß√£o.")
        st.markdown("---")
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Munic√≠pios", len(df_filtered), f"{len(df_municipios)} total")
        with col2:
            st.metric("UTPs", len(df_filtered['utp_id'].unique()), f"{len(utps_list)} total")
        with col3:
            st.metric("Estados", len(df_filtered['uf'].unique()), f"{len(ufs)} total")
        
        st.markdown("---")
        st.markdown("#### Mapa Interativo")
        
        if gdf is not None:
            gdf_filtered = gdf[gdf['uf'].isin(selected_ufs)].copy()
            if selected_utps:
                gdf_filtered = gdf_filtered[gdf_filtered['utp_id'].isin(selected_utps)]
            
            st.subheader(f"{len(selected_ufs)} Estado(s) | {len(gdf_filtered)} Munic√≠pios")
            render_map(gdf_filtered, title="Distribui√ß√£o Inicial")
        
        st.markdown("---")
        st.markdown("#### Composi√ß√£o das UTPs")
        
        utp_summary = df_filtered.groupby('utp_id').agg({
            'nm_mun': 'count',
            'sede_utp': 'sum',
            'regiao_metropolitana': lambda x: (x.notna() & (x != '')).sum()
        }).rename(columns={
            'nm_mun': 'Munic√≠pios',
            'sede_utp': 'Sedes',
            'regiao_metropolitana': 'Com RM'
        }).sort_values('Munic√≠pios', ascending=False).head(15)
        
        st.dataframe(utp_summary, use_container_width=True)
    
    # ==== TAB 2: P√ìS-CONSOLIDA√á√ÉO ====
    with tab2:
        st.markdown("### <span class='step-badge step-final'>FINAL</span> Ap√≥s Consolida√ß√£o", unsafe_allow_html=True)
        col_title, col_btn = st.columns([3, 1])
        with col_title:
            st.markdown("Mapa da distribui√ß√£o ap√≥s consolida√ß√£o de UTPs unit√°rias e limpeza territorial.")
        with col_btn:
            if st.button("Rodar Pipeline", use_container_width=True, key="btn_tab_run"):
                with st.spinner("Executando..."):
                    if run_consolidation():
                        st.success("Feito!")
                        st.rerun()
                    else:
                        st.error("Erro!")
        st.markdown("---")
        
        if consolidation_loader.is_executed():
            consolidations = consolidation_loader.get_consolidations()
            stats_summary = consolidation_loader.get_summary()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Consolida√ß√µes", stats_summary['total_consolidations'])
            with col2:
                st.metric("UTPs Reduzidas", f"{stats_summary['unique_sources']} ‚Üí {stats_summary['unique_targets']}")
            with col3:
                reduction = (stats_summary['unique_sources'] - stats_summary['unique_targets']) / stats_summary['unique_sources'] * 100
                st.metric("% Redu√ß√£o", f"{reduction:.1f}%")
            
            st.markdown("---")
            st.markdown("#### Mapa P√≥s-Consolida√ß√£o")
            
            # Aplicar consolida√ß√µes ao dataframe
            df_consolidated = consolidation_loader.apply_consolidations_to_dataframe(df_filtered)
            
            if gdf is not None:
                gdf_consolidated = consolidation_loader.apply_consolidations_to_dataframe(
                    gdf[gdf['uf'].isin(selected_ufs)].copy()
                )
                
                if selected_utps:
                    target_utps = set(c['target_utp'] for c in consolidations)
                    gdf_consolidated = gdf_consolidated[
                        gdf_consolidated['utp_id'].isin(target_utps | set(selected_utps))
                    ]
                
                st.subheader(f"{len(selected_ufs)} Estado(s) | {len(gdf_consolidated)} Munic√≠pios")
                render_map(gdf_consolidated, title="Distribui√ß√£o Consolidada")
            
            st.markdown("---")
            st.markdown("#### Registro de Consolida√ß√µes")
            
            # Preparar dados para planilha
            df_consolidations = consolidation_loader.export_as_dataframe()
            st.dataframe(df_consolidations, use_container_width=True, hide_index=True)
            
            # Download do resultado
            result_json = json.dumps(consolidation_loader.result, ensure_ascii=False, indent=2)
            st.download_button(
                label="Baixar Resultado de Consolida√ß√£o",
                data=result_json,
                file_name=f"consolidation_result_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                mime="application/json"
            )
        
        else:
            st.info("Nenhuma consolida√ß√£o em cache ainda.")
            st.markdown("""
            ### Como usar:
            
            1. **Execute a consolida√ß√£o** via seu c√≥digo (etapas 0-7)
            2. **O arquivo `consolidation_result.json` ser√° criado** em `data/`
            3. **Recarregue o dashboard** (F5 ou refresh)
            4. Os mapas comparativos aparecer√£o automaticamente
            
            O cache permanecer√° enquanto voc√™ n√£o clicar em üóëÔ∏è "Limpar" na sidebar.
            """)
    
    # ==== TAB 3: AN√ÅLISE DE DEPEND√äNCIAS ====
    with tab3:
        st.markdown("### <span class='step-badge step-final'>AN√ÅLISE</span> Depend√™ncias entre Sedes", unsafe_allow_html=True)
        st.markdown("An√°lise sede-a-sede para identificar hierarquias e depend√™ncias entre UTPs usando dados socioecon√¥micos e fluxos.")
        st.markdown("---")
        
        # Inicializar analisador com cache
        @st.cache_data(show_spinner="Analisando depend√™ncias entre sedes...")
        def run_sede_analysis():
            """
            Executa an√°lise de depend√™ncias e retorna resultados.
            
            IMPORTANTE: A an√°lise √© feita sobre a configura√ß√£o territorial AP√ìS consolida√ß√£o,
            se houver consolida√ß√µes em cache. Caso contr√°rio, usa a configura√ß√£o inicial.
            """
            # Passar consolidation_loader para usar dados consolidados
            analyzer = SedeAnalyzer(consolidation_loader=consolidation_loader)
            summary = analyzer.analyze_sede_dependencies()
            
            if summary.get('success'):
                df_table = analyzer.export_sede_comparison_table()
                return summary, df_table, analyzer.df_sede_analysis
            else:
                return summary, pd.DataFrame(), pd.DataFrame()
        
        # Executar an√°lise
        try:
            summary, df_display, df_raw = run_sede_analysis()
            
            if summary.get('success'):
                # === M√âTRICAS GERAIS ===
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Total de Sedes", summary['total_sedes'])
                
                with col2:
                    alert_count = summary['total_alertas']
                    st.metric("Alertas", alert_count, 
                             delta="Depend√™ncias" if alert_count > 0 else "Nenhum",
                             delta_color="inverse")
                
                with col3:
                    st.metric("Popula√ß√£o Total", f"{summary['populacao_total']:,}")
                
                with col4:
                    st.metric("Com Aeroporto", summary['sedes_com_aeroporto'])
                
                st.markdown("---")
                
                # === ALERTAS DE DEPEND√äNCIA ===
                st.markdown("#### Alertas de Depend√™ncia Funcional")
                st.caption("Sedes cujo principal fluxo vai para outra sede a at√© 2h de dist√¢ncia")
                
                sede_comparison.render_dependency_alerts(df_display)
                
                st.markdown("---")
                
                # === FILTROS E TABELA ===
                st.markdown("#### Tabela Comparativa de Sedes")
                
                # Filtros acima da tabela
                col_filter1, col_filter2, col_filter3 = st.columns(3)
                
                with col_filter1:
                    show_alerts_only = st.checkbox("Apenas Alertas", value=False)
                
                with col_filter2:
                    # Filtro por REGIC
                    regic_options = ['Todos'] + sorted(df_raw[df_raw['regic'] != '']['regic'].unique().tolist())
                    selected_regic = st.selectbox("Filtrar por REGIC", regic_options)
                
                with col_filter3:
                    # Filtro por aeroporto
                    filter_airport = st.selectbox("Filtrar Aeroporto", ["Todos", "Apenas com aeroporto", "Sem aeroporto"])
                
                # Aplicar filtros ao dataframe
                df_filtered_display = df_display.copy()
                df_filtered_raw = df_raw.copy()
                
                if selected_regic != 'Todos':
                    mask = df_raw['regic'] == selected_regic
                    df_filtered_display = df_display[mask]
                    df_filtered_raw = df_raw[mask]
                
                if filter_airport == "Apenas com aeroporto":
                    mask = df_display['Aeroporto'] == 'Sim'
                    df_filtered_display = df_filtered_display[mask]
                    df_filtered_raw = df_filtered_raw[df_raw['tem_aeroporto'] == True]
                elif filter_airport == "Sem aeroporto":
                    mask = df_display['Aeroporto'] == ''
                    df_filtered_display = df_filtered_display[mask]
                    df_filtered_raw = df_filtered_raw[df_raw['tem_aeroporto'] == False]
                
                # Renderizar tabela
                sede_comparison.render_sede_table(df_filtered_display, show_alerts_only)
                
                st.markdown("---")
                
                # === VISUALIZA√á√ïES ===
                st.markdown("#### An√°lises Visuais")
                
                # Gr√°ficos socioecon√¥micos
                sede_comparison.render_socioeconomic_charts(df_filtered_display)
                
                st.markdown("---")
                
                # Distribui√ß√£o REGIC
                sede_comparison.render_regic_distribution(df_filtered_display)
                
                st.markdown("---")
                
                # === EXPORTAR DADOS ===
                st.markdown("#### üíæ Exportar Dados")
                
                col_exp1, col_exp2 = st.columns(2)
                
                with col_exp1:
                    # Download CSV da tabela
                    csv = df_display.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="Baixar Tabela (CSV)",
                        data=csv,
                        file_name=f"analise_sedes_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv"
                    )
                
                with col_exp2:
                    # Download JSON dos alertas
                    if summary['total_alertas'] > 0:
                        alertas_json = df_raw[df_raw['tem_alerta_dependencia']]['alerta_detalhes'].tolist()
                        json_str = json.dumps(alertas_json, ensure_ascii=False, indent=2)
                        st.download_button(
                            label="Baixar Alertas (JSON)",
                            data=json_str,
                            file_name=f"alertas_dependencia_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
                            mime="application/json"
                        )
            
            else:
                st.error(f"Erro ao executar an√°lise: {summary.get('error', 'Erro desconhecido')}")
                st.info("""
                ### Como usar:
                
                1. Certifique-se de que o arquivo `data/initialization.json` est√° presente
                2. Verifique se a matriz de imped√¢ncia est√° dispon√≠vel em `data/01_raw/impedance/impedancias_filtradas_2h.csv`
                3. Recarregue o dashboard (F5)
                """)
        
        except Exception as e:
            st.error(f"Erro ao carregar an√°lise de sedes: {e}")
            import traceback
            with st.expander("Ver detalhes do erro"):
                st.code(traceback.format_exc())
    
    # === FOOTER ===
    st.markdown("---")
    st.markdown("""
    <div style='text-align: center; color: #666; font-size: 0.9rem; margin-top: 2rem;'>
        <p><strong>GeoValida</strong> ‚Ä¢ Consolida√ß√£o Territorial de UTPs</p>
        <p>Laborat√≥rio de Transportes ‚Ä¢ UFSC</p>
        <p style='font-size: 0.8rem; color: #999;'>Cache de consolida√ß√£o em: <code>data/consolidation_result.json</code></p>
    </div>
    """, unsafe_allow_html=True)
